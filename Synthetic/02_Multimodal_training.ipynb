{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107b6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "exp_id = np.load('exp_id.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4c4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loader\n",
    "\n",
    "class CustomDataset():\n",
    "    def __init__(self, fname_d, fname_l, transforms=True):\n",
    "        self.data = np.load(fname_d)\n",
    "        self.labels = np.load(fname_l)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = np.array(self.labels[index])\n",
    "        m1 = self.data[index,0:784].reshape(1,28,28).astype(float)\n",
    "        m2 = self.data[index,784:1568].reshape(1,28,28).astype(float)\n",
    "        m3 = self.data[index,1568:1568+20].reshape(20).astype(float)\n",
    "        # Transform to tensor\n",
    "        if self.transforms:\n",
    "            m1_as_tensor = torch.from_numpy(m1)\n",
    "            m2_as_tensor = torch.from_numpy(m2)\n",
    "            m3_as_tensor = torch.from_numpy(m3)\n",
    "            label_as_tensor = torch.from_numpy(label).type(torch.long)\n",
    "            \n",
    "        # Return image and the label\n",
    "        return (m1_as_tensor, m2_as_tensor, m3_as_tensor, label_as_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "\n",
    "## Model architecture\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, enc_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(16, 16, 3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(16, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(64* 5* 5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, enc_dim)\n",
    "            )\n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(enc_dim)\n",
    "        \n",
    "    def forward(self, m1):\n",
    "        x = self.encoder_cnn(m1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Fused_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Fused_net, self).__init__()\n",
    "       \n",
    "        self.fused_nn = torch.nn.Sequential(\n",
    "            nn.Linear(10+10+10+10, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(10, 2) ) \n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(40)\n",
    "                    \n",
    "    def forward(self, x1, x2, m3):\n",
    "        \n",
    "        x = torch.cat((x1, x2, m3), dim=1)\n",
    "#         x = self.norm(x)\n",
    "        x = self.fused_nn(x)\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5729cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def Accuracy(device, loader):\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            m1, m2, m3, labels = data\n",
    "            img1 = m1.to(device)\n",
    "            img2 = m2.to(device)\n",
    "            tab = m3.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # run the model on the test set to predict labels\n",
    "            enc_img1 = net1(img1)\n",
    "            enc_img2 = net1(img2)\n",
    "            outputs = net2(enc_img1, enc_img2, tab)\n",
    "            \n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, -1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51db2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(net1, net2 , train_loader, loss, optimizer, num_epochs, device):\n",
    "    best_accuracy = 0.0\n",
    "    losses =[]\n",
    "    \n",
    "    # Define your execution device\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    net1.to(device).train()\n",
    "    net2.to(device).train()\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        start_time = time.time()\n",
    "        for i, (m1, m2, m3, labels) in enumerate(train_loader, 0):\n",
    "            # get the inputs\n",
    "            img1 = Variable(m1.to(device))\n",
    "            img2 = Variable(m2.to(device))\n",
    "            tab = Variable(m3.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # run the model on the test set to predict labels\n",
    "            enc_img1 = net1(img1)\n",
    "            enc_img2 = net1(img2)\n",
    "            outputs = net2(enc_img1, enc_img2, tab)\n",
    "            \n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            losses.append(running_loss)\n",
    "            if i % 1000 == 999:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                \n",
    "        val_acc = Accuracy(device, test_loader)\n",
    "        print('Epoch', epoch+1, 'Train acc %d %%' % (Accuracy(device, train_loader)) , 'Val acc %d %%' % (val_acc) , \"Time elapsed: \", time.time() - start_time )\n",
    "        if val_acc > 95:\n",
    "            break\n",
    "            \n",
    "    return (losses)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d717e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    batch_size = 128\n",
    "    epochs = 20\n",
    "    custom_train_data = CustomDataset('D1_train.npy', 'D1_F'+str(exp_id)+'_label_train.npy')\n",
    "    custom_test_data = CustomDataset('D1_test.npy', 'D1_F'+str(exp_id)+'_label_test.npy')\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    net1 = Encoder(10).double()\n",
    "    net2 = Fused_net().double()\n",
    "    \n",
    "    train_loader = DataLoader(dataset=custom_train_data, shuffle=True, batch_size= batch_size)\n",
    "    test_loader   = DataLoader(dataset=custom_test_data, shuffle=False, batch_size= batch_size)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net1.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    optimizer.add_param_group(torch.optim.Adam(net2.parameters()).param_groups[0])\n",
    "    \n",
    "    loss = train(net1, net2, train_loader, loss_fn, optimizer, epochs , device)\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670f8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save trained model \n",
    "torch.save(net1, 'F'+ str(exp_id) +'_net1.pt')\n",
    "torch.save(net2, 'F'+ str(exp_id) +'_net2.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
